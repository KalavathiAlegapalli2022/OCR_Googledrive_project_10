# -*- coding: utf-8 -*-
"""Extract Text from XML .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sx0Og1VsLZRhbT-A0duQnLT2rRKigkmo

# Mount Google Drive and Import Required Libraries
"""

from google.colab import drive
import os
drive.mount('/content/drive')
print(" Google Drive mounted successfully.")
base_path = '/content/drive/MyDrive/CustomOCR'
print(f" Base directory set to: {base_path}")
base_path = '/content/drive/MyDrive/Custom_OCR_Project'
dataset_path = os.path.join(base_path, 'datasets')
model_dir = os.path.join(base_path, 'models')
results_path = os.path.join(base_path, 'results')
os.makedirs(dataset_path, exist_ok=True)
os.makedirs(model_dir, exist_ok=True)
os.makedirs(results_path, exist_ok=True)
print("\n Folder paths set up successfully:")
print(f"    Dataset Directory : {dataset_path}")
print(f"    Model Directory   : {model_dir}")
print(f"    Results Directory : {results_path}")

"""# Step 1: Importing required libraries"""

import os
from glob import glob
import pandas as pd
from xml.etree import ElementTree as et
from functools import reduce

"""# Step 2: Suppressing warnings for clean output"""

import warnings
warnings.filterwarnings('ignore')
xmlfiles = glob(base_path + '/data_images/*.xml')
xmlfiles = list(map(lambda x: x.replace('\\', '/'), xmlfiles))
print(f'Total XML files found: {len(xmlfiles)}')
print("\nXML file paths:")
for i, path in enumerate(xmlfiles[:5], 1):
    print(f"{i}. {path}")

"""# Step 5: Defining function to parse XML content &


# Step 6: Parsing all XML files
"""

def extract_text(filename):
    tree = et.parse(filename)
    root = tree.getroot()
    image_name = root.find('filename').text
    width = root.find('size/width').text
    height = root.find('size/height').text
    objs = root.findall('object')
    parser = []
    for obj in objs:
        name = obj.find('name').text
        bndbox = obj.find('bndbox')
        xmin = bndbox.find('xmin').text
        xmax = bndbox.find('xmax').text
        ymin = bndbox.find('ymin').text
        ymax = bndbox.find('ymax').text
        parser.append([image_name, width, height, name, xmin, xmax, ymin, ymax])
    return parser


parser_all = list(map(extract_text, xmlfiles))
print(f'Total parsed entries (file-wise): {len(parser_all)}')

print("\nShowing 4 annotations from first file:")
for i, annotation in enumerate(parser_all[0][:4], 1):
    print(f"{i}. {annotation}")

"""# Step 8: Flattening the parsed list into a single list of annotations"""

data = reduce(lambda x, y: x + y, parser_all)
print(f'Total number of bounding boxes extracted: {len(data)}')
# Step 9: Previewing a few annotations
print("\nPreview of parsed bounding boxes:")
for i, bbox in enumerate(data[:3], 1):
    print(f"{i}. {bbox}")

"""# Step 10: Creating DataFrame from the extracted annotations"""

df = pd.DataFrame(data, columns=['filename', 'width', 'height', 'name', 'xmin', 'xmax', 'ymin', 'ymax'])
print(' DataFrame created successfully!\n')
df.head()

"""# Step 11: Checking dataset information before conversion"""

print("DataFrame shape:")
print(df.shape)

print("\nValue counts of 'name' column:")
print(df['name'].value_counts())

print("\nDataFrame info:")
df.info()

"""# Step 12: Converting numeric columns from string to integer"""

cols = ['width','height','xmin','xmax','ymin','ymax']
df[cols] = df[cols].astype(int)
print("\n✅ Successfully converted width/height/bbox to integers")
print(df.info())

"""# Step 13: Normalizing bounding box coordinates"""

# Step 13: Normalizing bounding box coordinates
df['center_x'] = ((df['xmax'] + df['xmin']) / 2) / df['width']
df['center_y'] = ((df['ymax'] + df['ymin']) / 2) / df['height']
df['w'] = (df['xmax'] - df['xmin']) / df['width']
df['h'] = (df['ymax'] - df['ymin']) / df['height']

print("✅ Normalization completed\n")
# df[['filename', 'name', 'center_x', 'center_y', 'w', 'h']].head()
df.head()

"""# Step 14: Splitting data into train and test based on filenames"""

from sklearn.model_selection import train_test_split
train_files, test_files = train_test_split(df['filename'].unique(), test_size=0.2, random_state=42)

train_df = df[df['filename'].isin(train_files)]
test_df = df[df['filename'].isin(test_files)]

print(f"\nTraining samples: {len(train_df)}")
print(f"Testing samples: {len(test_df)}")

"""# Step 15: Assign ID to object names"""

def label_encoding(x):
    labels = {'Test Name':0, 'Value':1, 'Units':2, 'Reference Range':3}
    return labels[x]

train_df['id'] = train_df['name'].apply(label_encoding)
test_df['id'] = test_df['name'].apply(label_encoding)
train_df.head(10)

"""# Step 16: Save image and labels to text"""

from shutil import move
train_folder = base_path + '/data_images/train'
test_folder = base_path + '/data_images/test'
os.makedirs(train_folder, exist_ok=True)
os.makedirs(test_folder, exist_ok=True)

cols = ['filename','id','center_x','center_y', 'w', 'h']
groupby_obj_train = train_df[cols].groupby('filename')
groupby_obj_test = test_df[cols].groupby('filename')

print(f"Train folder created at: {train_folder}")
print(f"Test folder created at: {test_folder}")

print(f"\nNumber of training files: {len(groupby_obj_train)}")
print(f"Number of testing files: {len(groupby_obj_test)}")

"""# Step 17: Save each image in train/test folder and repective labels in .txt"""

def save_data(filename, folder_path, group_obj):
    src = os.path.join(base_path, 'datasets', filename)
    dst = os.path.join(folder_path, filename)
    move(src, dst)
    text_filename = os.path.join(folder_path, os.path.splitext(filename)[0]+'.txt')
    group_obj.get_group(filename).set_index('filename').to_csv(text_filename, sep=' ', index=False, header=False)

pd.Series(groupby_obj_train.groups.keys()).apply(save_data, args=(train_folder, groupby_obj_train))
pd.Series(groupby_obj_test.groups.keys()).apply(save_data, args=(test_folder, groupby_obj_test))

print(" All images and label files saved successfully.")
print(" Unique labels:", train_df['name'].unique())

print(f" Saved {len(groupby_obj_train)} training images and label files to {train_folder}")
print(f" Saved {len(groupby_obj_test)} testing images and label files to {test_folder}")
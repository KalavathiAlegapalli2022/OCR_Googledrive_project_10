# -*- coding: utf-8 -*-
"""Final_project10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16rKqCTq-9AnUtgKAaztM0avqFCwnetPn

# Custom-Object Character Recognition(OCR) on AWS (Google Drive/ Cloud Storage)

#### Task 1: Environment Setup

##  Task 1.1: Mounting Google Drive
"""

print("\n Task 1.1: Mounting Google Drive")
from google.colab import drive
drive.mount('/content/drive')

"""# ##  Defining Drive Paths for Dataset, Model, and Output Folders"""

import os
#  Defining base and subfolder paths for the project
base_path      = '/content/drive/MyDrive/CustomOCR'
dataset_path   = os.path.join(base_path, 'datasets')
model_dir      = os.path.join(base_path, 'models')
model_path     = os.path.join(model_dir, 'best.onnx')
results_path   = os.path.join(base_path, 'results')
print(" Folder paths set up successfully:")
print(f"    Dataset Directory : {dataset_path}")
print(f"    Model Directory   : {model_dir}")
print(f"    Results Directory : {results_path}")
print(f"    Model File Path   : {model_path}")

"""####  Task 1.2: Installing necessary dependencies

# Installing Python packages required for this project

"""

!pip install opencv-python-headless pytesseract numpy pandas matplotlib
!apt install tesseract-ocr -y

"""#  Task 2.0.2: Cloning YOLOv5 Repo and Setting Up in Drive"""

print(" Cloning YOLOv5 repository from GitHub...")
!git clone https://github.com/ultralytics/yolov5.git
print(" Moving YOLOv5 to Google Drive > CustomOCR/yolov5 ...")
!mv yolov5 /content/drive/MyDrive/CustomOCR/yolov5
os.chdir('/content/drive/MyDrive/CustomOCR/yolov5')
print(" Working directory set to: /content/drive/MyDrive/CustomOCR/yolov5")

"""# Installing YOLOv5 requirements"""

!pip install -r requirements.txt

"""#  Task 2.0: Preparing data.yaml for YOLOv5"""

import os
import shutil
import random

# === CONFIG ===
ROOT_DIR = "/content/drive/MyDrive/CustomOCR"
SRC_IMAGES_DIR = ROOT_DIR
SRC_LABELS_DIR = os.path.join(ROOT_DIR, "labels_source")
DST_IMAGES_DIR = os.path.join(ROOT_DIR, "data_images")
DST_LABELS_DIR = os.path.join(ROOT_DIR, "data_labels")
TRAIN_RATIO = 0.8  # 80% train, 20% test

# === CREATE FOLDERS ===
for folder in ["train", "test"]:
    os.makedirs(os.path.join(DST_IMAGES_DIR, folder), exist_ok=True)
    os.makedirs(os.path.join(DST_LABELS_DIR, folder), exist_ok=True)

# === GET IMAGES ===
all_images = [f for f in os.listdir(SRC_IMAGES_DIR) if f.lower().endswith(('.jpg','.png'))]

# === CHECK FOR LABELS ===
labeled_images = []
missing_labels = []

for img_file in all_images:
    label_file = img_file.rsplit('.',1)[0] + ".txt"
    label_path = os.path.join(SRC_LABELS_DIR, label_file)
    if os.path.exists(label_path):
        labeled_images.append(img_file)
    else:
        missing_labels.append(img_file)

if missing_labels:
    print("Warning: These images have NO labels and will be skipped:")
    for img in missing_labels:
        print(img)

# === SHUFFLE AND SPLIT ===
random.shuffle(labeled_images)
split_idx = int(TRAIN_RATIO * len(labeled_images))
train_imgs = labeled_images[:split_idx]
test_imgs = labeled_images[split_idx:]

# === MOVE FILES ===
def move_files(file_list, dataset_type):
    for img_file in file_list:
        # move image
        shutil.move(os.path.join(SRC_IMAGES_DIR, img_file),
                    os.path.join(DST_IMAGES_DIR, dataset_type, img_file))
        # move label
        label_file = img_file.rsplit('.',1)[0] + ".txt"
        shutil.move(os.path.join(SRC_LABELS_DIR, label_file),
                    os.path.join(DST_LABELS_DIR, dataset_type, label_file))

move_files(train_imgs, "train")
move_files(test_imgs, "test")

# === PRINT FINAL TREE ===
def print_tree(root, prefix=""):
    print(prefix + os.path.basename(root) + "/")
    prefix += "    "
    for f in sorted(os.listdir(root)):
        path = os.path.join(root, f)
        if os.path.isdir(path):
            print_tree(path, prefix)
        else:
            print(prefix + f)

print("\n=== Final Dataset Tree ===")
print_tree(DST_IMAGES_DIR)
print_tree(DST_LABELS_DIR)

import os
import shutil
import random

# Paths
images_dir = '../'  # all .jpg images
labels_dir = '../data_labels'
train_images_dir = '../data_images/train'
test_images_dir = '../data_images/test'
train_labels_dir = os.path.join(labels_dir, 'train')
test_labels_dir = os.path.join(labels_dir, 'test')

# Create folders if they don't exist
os.makedirs(train_images_dir, exist_ok=True)
os.makedirs(test_images_dir, exist_ok=True)
os.makedirs(train_labels_dir, exist_ok=True)
os.makedirs(test_labels_dir, exist_ok=True)

# List all images
images = [f for f in os.listdir(images_dir) if f.endswith('.jpg')]

# Shuffle and split 80:20
random.shuffle(images)
split = int(0.8 * len(images))
train_files = images[:split]
test_files = images[split:]

# Function to copy images and ensure labels exist
def copy_images_and_labels(files, images_dest, labels_dest):
    for img in files:
        # Copy image
        shutil.copy(os.path.join(images_dir, img), images_dest)

        # Ensure label file exists
        label_name = img.replace('.jpg', '.txt')
        src_label = os.path.join(labels_dir, label_name)
        dst_label = os.path.join(labels_dest, label_name)

        if os.path.exists(src_label):
            shutil.copy(src_label, dst_label)
        else:
            # Create empty label file if missing
            open(dst_label, 'w').close()

# Process train and test sets
copy_images_and_labels(train_files, train_images_dir, train_labels_dir)
copy_images_and_labels(test_files, test_images_dir, test_labels_dir)

print(f"Train images: {len(os.listdir(train_images_dir))}")
print(f"Train labels: {len(os.listdir(train_labels_dir))}")
print(f"Test images: {len(os.listdir(test_images_dir))}")
print(f"Test labels: {len(os.listdir(test_labels_dir))}")

import shutil
import glob
import cv2
dataset_path = '/content/drive/MyDrive/CustomOCR/datasets'
split_path = '/content/drive/MyDrive/CustomOCR/data_images'
train_img_dir = os.path.join(split_path, 'train')
test_img_dir = os.path.join(split_path, 'test')
yaml_path = '/content/drive/MyDrive/CustomOCR/yolov5/data.yaml'
yaml_content = f'''\
train: ../data_images/train
val: ../data_images/test

nc: 4
names: ["Test Name", "Value", "Units", "Reference Range"]
'''

with open(yaml_path, 'w') as f:
    f.write(yaml_content)

print(f" data.yaml file created at:")
print(f"    {yaml_path}")

"""# Task 2.1: model training (200 epochs)"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/CustomOCR/yolov5

!python train.py \
  --img 640 \
  --batch 2 \
  --epochs 200 \
  --data data.yaml \
  --weights yolov5s.pt \
  --project runs/train \
  --name Model2 \
  --exist-ok

os.environ['WANDB_MODE'] = 'disabled'
os.chdir('/content/drive/MyDrive/CustomOCR/yolov5')
print(" Working directory: yolov5")
print(" Starting training (200 epochs)...")
# !WANDB_MODE=disabled python train.py --data data.yaml --weights yolov5s.pt --img 640 --batch-size 2 --name Model --epochs 50
!WANDB_MODE=disabled python train.py --data data.yaml --weights runs/train/Model2/weights/best.pt --img 640 --batch-size 2 --name Model --epochs 200

"""#  Task 2.4: Exporting best.pt to ONNX format and saving both files to /models/"""

# Commented out IPython magic to ensure Python compatibility.
print(" Exporting best.pt to ONNX format...")
best_pt_path = "/content/drive/MyDrive/CustomOCR/yolov5/runs/train/Model5/weights/best.pt"
# %cd /content/drive/MyDrive/CustomOCR/yolov5
!python export.py --weights {best_pt_path} --include onnx --simplify --opset 12
!mv runs/train/Model5/weights/best.onnx /content/drive/MyDrive/CustomOCR/models/best.onnx
!cp {best_pt_path} /content/drive/MyDrive/CustomOCR/models/best.pt

print("Both best.pt and best.onnx saved to: /MyDrive/CustomOCR/models/")

"""#####  Task 4: Dataset Preview

##  Task 4.1: Checking if dataset images are present
"""

import glob
import matplotlib.pyplot as plt
dataset_path = '/content/drive/MyDrive/CustomOCR/datasets'
sample_images = glob.glob(os.path.join(dataset_path, '*.jpg'))
print(f"Found {len(sample_images)} images in dataset.")

if sample_images:

    img = cv2.imread(sample_images[0])
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.title("Sample Image")
    plt.axis(False)
    plt.show()
else:
    print("âš ï¸ No .jpg images found in the datasets folder.")

"""#####  Task 5: Model Loading &  Task 6: YOLOv5 Inference and OCR"""

##  Task 5.1: Loading pretrained YOLOv5 ONNX model
import numpy as np
print("\n Task 5.1: Loading YOLOv5 ONNX Model from Drive")

model_path = '/content/drive/MyDrive/CustomOCR/models/best.onnx'

if not os.path.exists(model_path):
    print(f"\n ERROR: Model file not found at:\n   {model_path}")
    print(" Please ensure the ONNX model has been successfully exported and saved.")
else:
    print(f"\n Found ONNX model at:\n   {model_path}")
    print(" Initializing YOLOv5 ONNX model using OpenCV DNN module...")
    yolo_model = cv2.dnn.readNetFromONNX(model_path)
    yolo_model.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
    yolo_model.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
    print(" YOLOv5 ONNX model loaded and ready for inference.")

"""## Task 7: Executing OCR Pipeline and Saving Results"""

#  Final Updated YOLOv3 ONNX + Tesseract OCR Pipeline with Smart Units Correction
import numpy as np
import pytesseract as py
import pandas as pd
import matplotlib.pyplot as plt
import csv
import yaml
from collections import Counter
base_path = '/content/drive/MyDrive/CustomOCR'
image_name = 'thyrocare_0_517.jpg'
image_path = os.path.join(base_path, 'data_images/test', image_name)
onnx_model_path = os.path.join(base_path, 'models/best.onnx')
output_dir = os.path.join(base_path, 'results/onnx_output')
os.makedirs(output_dir, exist_ok=True)

output_csv = os.path.join(output_dir, image_name.replace('.jpg', '_output.csv'))
output_yaml = os.path.join(output_dir, image_name.replace('.jpg', '_output.yaml'))
output_img = os.path.join(output_dir, image_name.replace('.jpg', '_annotated.jpg'))
def load_model():
    model = cv2.dnn.readNetFromONNX(onnx_model_path)
    model.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
    model.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
    return model
def predict(model, image):
    wh = 640
    h, w, _ = image.shape
    max_dim = max(h, w)
    square = np.zeros((max_dim, max_dim, 3), dtype=np.uint8)
    square[:h, :w] = image
    blob = cv2.dnn.blobFromImage(square, 1/255, (wh, wh), swapRB=True, crop=False)
    model.setInput(blob)
    preds = model.forward()
    return preds, square
def process(preds, image, conf=0.4, score=0.25):
    boxes, scores, class_ids = [], [], []
    h, w = image.shape[:2]
    x_scale, y_scale = w / 640, h / 640
    for det in preds[0]:
        if det[4] > conf:
            cls_scores = det[5:]
            cls_id = int(np.argmax(cls_scores))
            if cls_scores[cls_id] > score:
                cx, cy, bw, bh = det[0:4]
                x = int((cx - bw/2) * x_scale)
                y = int((cy - bh/2) * y_scale)
                boxes.append([x, y, int(bw * x_scale), int(bh * y_scale)])
                scores.append(float(det[4]))
                class_ids.append(cls_id)
    idx = cv2.dnn.NMSBoxes(boxes, scores, score, 0.45)
    return idx, boxes, class_ids
def ocr_fields(image, boxes, idx, class_ids):
    field_map = {0: 'Test Name', 1: 'Value', 2: 'Units', 3: 'Reference Range'}
    data = {k: [] for k in field_map.values()}
    for i in idx.flatten():
        x, y, w, h = boxes[i]
        crop = image[y:y+h, x:x+w]
        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
        gray = cv2.resize(gray, None, fx=3, fy=3)
        blur = cv2.GaussianBlur(gray, (5, 5), 0)
        _, th = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        roi = cv2.bitwise_not(th)
        try:
            text = py.image_to_string(roi, config='--oem 3 --psm 6').strip()
        except:
            text = ""
        label = field_map.get(class_ids[i], f"Class {class_ids[i]}")
        lines = [t.strip() for t in text.splitlines() if t.strip()]
        data[label].extend(lines)
    auto_units = []
    for t in data['Reference Range']:
        if '/' in t or 'IU' in t.upper() or 'ml' in t.lower() or 'g/' in t.lower():
            auto_units.append(t)
    data['Reference Range'] = [t for t in data['Reference Range'] if t not in auto_units]
    data['Units'].extend(auto_units)
    for label in ['Value', 'Units', 'Reference Range', 'Test Name']:
        items = data[label]
        if items:
            print(f"ðŸ“Œ Class: {label}, Text: {items}","\n")

    return data
def save_display(data):
    df = pd.DataFrame(data)
    final = pd.DataFrame()
    for col in df.columns:
        exploded = pd.DataFrame(df[col].explode()).reset_index(drop=True)
        exploded.columns = [col]
        final = pd.concat([final, exploded], axis=1)

    final.to_csv(output_csv, index=False, quoting=csv.QUOTE_NONNUMERIC)
    with open(output_yaml, 'w') as f:
        yaml.dump(final.fillna('').values.tolist(), f, allow_unicode=True)

    print("\n CSV:", output_csv)
    print(" YAML:", output_yaml)
    display(final)
    return final
def draw(image, boxes, idx, class_ids):
    field_map = {0: 'Test Name', 1: 'Value', 2: 'Units', 3: 'Reference Range'}
    for i in idx.flatten():
        x, y, w, h = boxes[i]
        label = field_map.get(class_ids[i], f"Class {class_ids[i]}")
        cv2.rectangle(image, (x, y), (x+w, y+h), (0,255,0), 2)
        cv2.putText(image, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)
    return image
if not os.path.exists(image_path):
    print(" Image not found:", image_path)
else:
    img = cv2.imread(image_path)
    if img is None:
        print("Could not load image.")
    else:
        model = load_model()
        preds, yolo_img = predict(model, img)
        idx, boxes, class_ids = process(preds, yolo_img)

        fields = ocr_fields(img, boxes, idx, class_ids)
        for cls in ['Value', 'Units', 'Reference Range', 'Test Name']:
            count = len(fields.get(cls, []))
            print(f" Detected {count} for '{cls}'")

        df = save_display(fields)

        annotated = draw(img.copy(), boxes, idx, class_ids)
        cv2.imwrite(output_img, annotated)
        plt.figure(figsize=(10,10))
        plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))
        plt.title("Annotated Image")
        plt.axis('off')
        plt.show()

"""####  Task 8: Generating Report"""

from datetime import datetime
custom_save_path = '/content/drive/MyDrive/CustomOCR'
report_path = os.path.join(custom_save_path, f"final_report_{datetime.now().strftime('%Y%m%d')}.txt")
csv_path = os.path.join(custom_save_path, 'results', 'ocr_results.csv')
gt_csv_path = os.path.join(custom_save_path, 'results', 'ground_truth.csv')  # expected location
with open(report_path, 'w') as f:
    f.write(" Project 10 - Custom OCR Report\n")
    f.write("Model used: YOLOv3 (ONNX)\n")
    f.write("OCR Engine: Tesseract\n")

    if sample_images and os.path.exists(model_path):
        f.write(f"Processed image: {sample_images[0]}\n")
        f.write(f"OCR output saved at: {csv_path}\n")
    else:
        f.write("No image processed or model missing.\n")

    if os.path.exists(gt_csv_path) and 'match_scores' in locals():
        f.write("\n Accuracy Summary:\n")
        for col, score in match_scores:
            f.write(f"- {col}: {score}%\n")
    else:
        f.write("\n Ground truth CSV not found or match_scores missing. Accuracy evaluation skipped.\n")

print(f" Report saved to: {report_path}")